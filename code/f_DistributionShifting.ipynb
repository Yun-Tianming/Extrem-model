{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# 解决内核挂掉的问题\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]  =  \"TRUE\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage.transform import resize\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "from torch import LongTensor, FloatTensor\n",
    "from torchvision.utils import save_image\n",
    "import sys\n",
    "gpu_id = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###  常规定义\n",
    "class NWSDataset(Dataset):\n",
    "    \"\"\"\n",
    "    NWS Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self, fake='../data/fake.pt', c=0.75, i=1, n=2557  ### 初始化参数c、i，影响结果和速率；n是数据集数量\n",
    "    ):\n",
    "        val = int(n * (c ** i))\n",
    "        self.real = torch.load('../data/train.pt').cuda(gpu_id)\n",
    "        self.real.requires_grad = False\n",
    "        self.fake = torch.load(fake).cuda(gpu_id)\n",
    "#         self.fake.requires_grad = False\n",
    "\n",
    "        self.realdata = torch.cat([self.real[:val], self.fake[:-1 * val]], 0) #选择性拼接，训练集和生成结果都算分布模型训练集\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.realdata.shape[0]\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.realdata[item]\n",
    "\n",
    "\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "\n",
    "\n",
    "def convTBNReLU(in_channels, out_channels, kernel_size=4, stride=2, padding=1):\n",
    "    return nn.Sequential(\n",
    "        nn.ConvTranspose2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "        ),\n",
    "        nn.InstanceNorm2d(out_channels),\n",
    "        nn.LeakyReLU(0.2, True),\n",
    "    )\n",
    "\n",
    "\n",
    "def convBNReLU(in_channels, out_channels, kernel_size=4, stride=2, padding=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "        ),\n",
    "        nn.InstanceNorm2d(out_channels),\n",
    "        nn.LeakyReLU(0.2, True),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 模型定义\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Generator, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.block1 = convTBNReLU(in_channels, 512, 4, 1, 0)\n",
    "        self.block2 = convTBNReLU(512, 256)\n",
    "        self.block3 = convTBNReLU(256, 128)\n",
    "        self.block4 = convTBNReLU(128, 64)\n",
    "        self.block5 = nn.ConvTranspose2d(64, out_channels, 4, 2, 1)\n",
    "\n",
    "    def forward(self, noise):\n",
    "        out = self.block1(noise)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        out = self.block4(out)\n",
    "        return torch.tanh(self.block5(out))\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.block1 = convBNReLU(self.in_channels, 64)\n",
    "        self.block2 = convBNReLU(64, 128)\n",
    "        self.block3 = convBNReLU(128, 256)\n",
    "        self.block4 = convBNReLU(256, 512)\n",
    "        self.block5 = nn.Conv2d(512, 64, 4, 1, 0)\n",
    "        self.source = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.block1(input)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        out = self.block4(out)\n",
    "        out = self.block5(out)\n",
    "        size = out.shape[0]\n",
    "        out = out.view(size, -1)\n",
    "        source = torch.sigmoid(self.source(out))\n",
    "        return source\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 一般参数定义\n",
    "latentdim = 20\n",
    "criterionSource = nn.BCELoss()\n",
    "G = Generator(in_channels=latentdim, out_channels=1).cuda(gpu_id)\n",
    "D = Discriminator(in_channels=1).cuda(gpu_id)\n",
    "G.apply(weights_init_normal)\n",
    "D.apply(weights_init_normal)\n",
    "\n",
    "optimizerG = optim.Adam(G.parameters(), lr=0.00002, betas=(0.5, 0.999))\n",
    "optimizerD = optim.Adam(D.parameters(), lr=0.00001, betas=(0.5, 0.999))\n",
    "static_z = Variable(FloatTensor(torch.randn((81, latentdim, 1, 1)))).cuda(gpu_id)\n",
    "\n",
    "\n",
    "def sample_image(stage, epoch):\n",
    "    static_sample = G(static_z).detach().cpu()\n",
    "    static_sample = (static_sample + 1) / 2.0\n",
    "    save_image(static_sample, DIRNAME + \"stage%depoch%d.png\" % (stage, epoch), nrow=9)\n",
    "\n",
    "\n",
    "c = 0.75\n",
    "k = 10\n",
    "DIRNAME = '../DistShift/'\n",
    "os.makedirs(DIRNAME, exist_ok=True)\n",
    "board = SummaryWriter(log_dir=DIRNAME)\n",
    "\n",
    "G.load_state_dict(torch.load('../DCGAN/G999.pt'))\n",
    "D.load_state_dict(torch.load('../DCGAN/D999.pt'))\n",
    "step = 0\n",
    "fake_name = '../data/fake.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1        0\n",
      "1        1\n",
      "1        2\n",
      "1        3\n",
      "1        4\n",
      "1        5\n",
      "1        6\n",
      "1        7\n",
      "1        8\n",
      "1        9\n",
      "1        10\n",
      "1        11\n",
      "1        12\n",
      "1        13\n",
      "1        14\n",
      "1        15\n",
      "1        16\n",
      "1        17\n",
      "1        18\n",
      "1        19\n",
      "1        20\n",
      "1        21\n",
      "1        22\n",
      "1        23\n",
      "1        24\n",
      "1        25\n",
      "1        26\n",
      "1        27\n",
      "1        28\n",
      "1        29\n",
      "1        30\n",
      "1        31\n",
      "1        32\n",
      "1        33\n",
      "1        34\n",
      "1        35\n",
      "1        36\n",
      "1        37\n",
      "1        38\n",
      "1        39\n",
      "1        40\n",
      "1        41\n",
      "1        42\n",
      "1        43\n",
      "1        44\n",
      "1        45\n",
      "1        46\n",
      "1        47\n",
      "1        48\n",
      "1        49\n",
      "1        50\n",
      "1        51\n",
      "1        52\n",
      "1        53\n",
      "1        54\n",
      "1        55\n",
      "1        56\n",
      "1        57\n",
      "1        58\n",
      "1        59\n",
      "1        60\n",
      "1        61\n",
      "1        62\n",
      "1        63\n",
      "1        64\n",
      "1        65\n",
      "1        66\n",
      "1        67\n",
      "1        68\n",
      "1        69\n",
      "1        70\n",
      "1        71\n",
      "1        72\n",
      "1        73\n",
      "1        74\n",
      "1        75\n",
      "1        76\n",
      "1        77\n",
      "1        78\n",
      "1        79\n",
      "1        80\n",
      "1        81\n",
      "1        82\n",
      "1        83\n",
      "1        84\n",
      "1        85\n",
      "1        86\n",
      "1        87\n",
      "1        88\n",
      "1        89\n",
      "1        90\n",
      "1        91\n",
      "1        92\n",
      "1        93\n",
      "1        94\n",
      "1        95\n",
      "1        96\n",
      "1        97\n",
      "1        98\n",
      "1        99\n",
      "2        0\n",
      "2        1\n",
      "2        2\n",
      "2        3\n",
      "2        4\n",
      "2        5\n",
      "2        6\n",
      "2        7\n",
      "2        8\n",
      "2        9\n",
      "2        10\n",
      "2        11\n",
      "2        12\n",
      "2        13\n",
      "2        14\n",
      "2        15\n",
      "2        16\n",
      "2        17\n",
      "2        18\n",
      "2        19\n",
      "2        20\n",
      "2        21\n",
      "2        22\n",
      "2        23\n",
      "2        24\n",
      "2        25\n",
      "2        26\n",
      "2        27\n",
      "2        28\n",
      "2        29\n",
      "2        30\n",
      "2        31\n",
      "2        32\n",
      "2        33\n",
      "2        34\n",
      "2        35\n",
      "2        36\n",
      "2        37\n",
      "2        38\n",
      "2        39\n",
      "2        40\n",
      "2        41\n",
      "2        42\n",
      "2        43\n",
      "2        44\n",
      "2        45\n",
      "2        46\n",
      "2        47\n",
      "2        48\n",
      "2        49\n",
      "2        50\n",
      "2        51\n",
      "2        52\n",
      "2        53\n",
      "2        54\n",
      "2        55\n",
      "2        56\n",
      "2        57\n",
      "2        58\n",
      "2        59\n",
      "2        60\n",
      "2        61\n",
      "2        62\n",
      "2        63\n",
      "2        64\n",
      "2        65\n",
      "2        66\n",
      "2        67\n",
      "2        68\n",
      "2        69\n",
      "2        70\n",
      "2        71\n",
      "2        72\n",
      "2        73\n",
      "2        74\n",
      "2        75\n",
      "2        76\n",
      "2        77\n",
      "2        78\n",
      "2        79\n",
      "2        80\n",
      "2        81\n",
      "2        82\n",
      "2        83\n",
      "2        84\n",
      "2        85\n",
      "2        86\n",
      "2        87\n",
      "2        88\n",
      "2        89\n",
      "2        90\n",
      "2        91\n",
      "2        92\n",
      "2        93\n",
      "2        94\n",
      "2        95\n",
      "2        96\n",
      "2        97\n",
      "2        98\n",
      "2        99\n",
      "3        0\n",
      "3        1\n",
      "3        2\n",
      "3        3\n",
      "3        4\n",
      "3        5\n",
      "3        6\n",
      "3        7\n",
      "3        8\n",
      "3        9\n",
      "3        10\n",
      "3        11\n",
      "3        12\n",
      "3        13\n",
      "3        14\n",
      "3        15\n",
      "3        16\n",
      "3        17\n",
      "3        18\n",
      "3        19\n",
      "3        20\n",
      "3        21\n",
      "3        22\n",
      "3        23\n",
      "3        24\n",
      "3        25\n",
      "3        26\n",
      "3        27\n",
      "3        28\n",
      "3        29\n",
      "3        30\n",
      "3        31\n",
      "3        32\n",
      "3        33\n",
      "3        34\n",
      "3        35\n",
      "3        36\n",
      "3        37\n",
      "3        38\n",
      "3        39\n",
      "3        40\n",
      "3        41\n",
      "3        42\n",
      "3        43\n",
      "3        44\n",
      "3        45\n",
      "3        46\n",
      "3        47\n",
      "3        48\n",
      "3        49\n",
      "3        50\n",
      "3        51\n",
      "3        52\n",
      "3        53\n",
      "3        54\n",
      "3        55\n",
      "3        56\n",
      "3        57\n",
      "3        58\n",
      "3        59\n",
      "3        60\n",
      "3        61\n",
      "3        62\n",
      "3        63\n",
      "3        64\n",
      "3        65\n",
      "3        66\n",
      "3        67\n",
      "3        68\n",
      "3        69\n",
      "3        70\n",
      "3        71\n",
      "3        72\n",
      "3        73\n",
      "3        74\n",
      "3        75\n",
      "3        76\n",
      "3        77\n",
      "3        78\n",
      "3        79\n",
      "3        80\n",
      "3        81\n",
      "3        82\n",
      "3        83\n",
      "3        84\n",
      "3        85\n",
      "3        86\n",
      "3        87\n",
      "3        88\n",
      "3        89\n",
      "3        90\n",
      "3        91\n",
      "3        92\n",
      "3        93\n",
      "3        94\n",
      "3        95\n",
      "3        96\n",
      "3        97\n",
      "3        98\n",
      "3        99\n",
      "4        0\n",
      "4        1\n",
      "4        2\n",
      "4        3\n",
      "4        4\n",
      "4        5\n",
      "4        6\n",
      "4        7\n",
      "4        8\n",
      "4        9\n",
      "4        10\n",
      "4        11\n",
      "4        12\n",
      "4        13\n",
      "4        14\n",
      "4        15\n",
      "4        16\n",
      "4        17\n",
      "4        18\n",
      "4        19\n",
      "4        20\n",
      "4        21\n",
      "4        22\n",
      "4        23\n",
      "4        24\n",
      "4        25\n",
      "4        26\n",
      "4        27\n",
      "4        28\n",
      "4        29\n",
      "4        30\n",
      "4        31\n",
      "4        32\n",
      "4        33\n",
      "4        34\n",
      "4        35\n",
      "4        36\n",
      "4        37\n",
      "4        38\n",
      "4        39\n",
      "4        40\n",
      "4        41\n",
      "4        42\n",
      "4        43\n",
      "4        44\n",
      "4        45\n",
      "4        46\n",
      "4        47\n",
      "4        48\n",
      "4        49\n",
      "4        50\n",
      "4        51\n",
      "4        52\n",
      "4        53\n",
      "4        54\n",
      "4        55\n",
      "4        56\n",
      "4        57\n",
      "4        58\n",
      "4        59\n",
      "4        60\n",
      "4        61\n",
      "4        62\n",
      "4        63\n",
      "4        64\n",
      "4        65\n",
      "4        66\n",
      "4        67\n",
      "4        68\n",
      "4        69\n",
      "4        70\n",
      "4        71\n",
      "4        72\n",
      "4        73\n",
      "4        74\n",
      "4        75\n",
      "4        76\n",
      "4        77\n",
      "4        78\n",
      "4        79\n",
      "4        80\n",
      "4        81\n",
      "4        82\n",
      "4        83\n",
      "4        84\n",
      "4        85\n",
      "4        86\n",
      "4        87\n",
      "4        88\n",
      "4        89\n",
      "4        90\n",
      "4        91\n",
      "4        92\n",
      "4        93\n",
      "4        94\n",
      "4        95\n",
      "4        96\n",
      "4        97\n",
      "4        98\n",
      "4        99\n",
      "5        0\n",
      "5        1\n",
      "5        2\n",
      "5        3\n",
      "5        4\n",
      "5        5\n",
      "5        6\n",
      "5        7\n",
      "5        8\n",
      "5        9\n",
      "5        10\n",
      "5        11\n",
      "5        12\n",
      "5        13\n",
      "5        14\n",
      "5        15\n",
      "5        16\n",
      "5        17\n",
      "5        18\n",
      "5        19\n",
      "5        20\n",
      "5        21\n",
      "5        22\n",
      "5        23\n",
      "5        24\n",
      "5        25\n",
      "5        26\n",
      "5        27\n",
      "5        28\n",
      "5        29\n",
      "5        30\n",
      "5        31\n",
      "5        32\n",
      "5        33\n",
      "5        34\n",
      "5        35\n",
      "5        36\n",
      "5        37\n",
      "5        38\n",
      "5        39\n",
      "5        40\n",
      "5        41\n",
      "5        42\n",
      "5        43\n",
      "5        44\n",
      "5        45\n",
      "5        46\n",
      "5        47\n",
      "5        48\n",
      "5        49\n",
      "5        50\n",
      "5        51\n",
      "5        52\n",
      "5        53\n",
      "5        54\n",
      "5        55\n",
      "5        56\n",
      "5        57\n",
      "5        58\n",
      "5        59\n",
      "5        60\n",
      "5        61\n",
      "5        62\n",
      "5        63\n",
      "5        64\n",
      "5        65\n",
      "5        66\n",
      "5        67\n",
      "5        68\n",
      "5        69\n",
      "5        70\n",
      "5        71\n",
      "5        72\n",
      "5        73\n",
      "5        74\n",
      "5        75\n",
      "5        76\n",
      "5        77\n",
      "5        78\n",
      "5        79\n",
      "5        80\n",
      "5        81\n",
      "5        82\n",
      "5        83\n",
      "5        84\n",
      "5        85\n",
      "5        86\n",
      "5        87\n",
      "5        88\n",
      "5        89\n",
      "5        90\n",
      "5        91\n",
      "5        92\n",
      "5        93\n",
      "5        94\n",
      "5        95\n",
      "5        96\n",
      "5        97\n",
      "5        98\n",
      "5        99\n",
      "6        0\n",
      "6        1\n",
      "6        2\n",
      "6        3\n",
      "6        4\n",
      "6        5\n",
      "6        6\n",
      "6        7\n",
      "6        8\n",
      "6        9\n",
      "6        10\n",
      "6        11\n",
      "6        12\n",
      "6        13\n",
      "6        14\n",
      "6        15\n",
      "6        16\n",
      "6        17\n",
      "6        18\n",
      "6        19\n",
      "6        20\n",
      "6        21\n",
      "6        22\n",
      "6        23\n",
      "6        24\n",
      "6        25\n",
      "6        26\n",
      "6        27\n",
      "6        28\n",
      "6        29\n",
      "6        30\n",
      "6        31\n",
      "6        32\n",
      "6        33\n",
      "6        34\n",
      "6        35\n",
      "6        36\n",
      "6        37\n",
      "6        38\n",
      "6        39\n",
      "6        40\n",
      "6        41\n",
      "6        42\n",
      "6        43\n",
      "6        44\n",
      "6        45\n",
      "6        46\n",
      "6        47\n",
      "6        48\n",
      "6        49\n",
      "6        50\n",
      "6        51\n",
      "6        52\n",
      "6        53\n",
      "6        54\n",
      "6        55\n",
      "6        56\n",
      "6        57\n",
      "6        58\n",
      "6        59\n",
      "6        60\n",
      "6        61\n",
      "6        62\n",
      "6        63\n",
      "6        64\n",
      "6        65\n",
      "6        66\n",
      "6        67\n",
      "6        68\n",
      "6        69\n",
      "6        70\n",
      "6        71\n",
      "6        72\n",
      "6        73\n",
      "6        74\n",
      "6        75\n",
      "6        76\n",
      "6        77\n",
      "6        78\n",
      "6        79\n",
      "6        80\n",
      "6        81\n",
      "6        82\n",
      "6        83\n",
      "6        84\n",
      "6        85\n",
      "6        86\n",
      "6        87\n",
      "6        88\n",
      "6        89\n",
      "6        90\n",
      "6        91\n",
      "6        92\n",
      "6        93\n",
      "6        94\n",
      "6        95\n",
      "6        96\n",
      "6        97\n",
      "6        98\n",
      "6        99\n",
      "7        0\n",
      "7        1\n",
      "7        2\n",
      "7        3\n",
      "7        4\n",
      "7        5\n",
      "7        6\n",
      "7        7\n",
      "7        8\n",
      "7        9\n",
      "7        10\n",
      "7        11\n",
      "7        12\n",
      "7        13\n",
      "7        14\n",
      "7        15\n",
      "7        16\n",
      "7        17\n",
      "7        18\n",
      "7        19\n",
      "7        20\n",
      "7        21\n",
      "7        22\n",
      "7        23\n",
      "7        24\n",
      "7        25\n",
      "7        26\n",
      "7        27\n",
      "7        28\n",
      "7        29\n",
      "7        30\n",
      "7        31\n",
      "7        32\n",
      "7        33\n",
      "7        34\n",
      "7        35\n",
      "7        36\n",
      "7        37\n",
      "7        38\n",
      "7        39\n",
      "7        40\n",
      "7        41\n",
      "7        42\n",
      "7        43\n",
      "7        44\n",
      "7        45\n",
      "7        46\n",
      "7        47\n",
      "7        48\n",
      "7        49\n",
      "7        50\n",
      "7        51\n",
      "7        52\n",
      "7        53\n",
      "7        54\n",
      "7        55\n",
      "7        56\n",
      "7        57\n",
      "7        58\n",
      "7        59\n",
      "7        60\n",
      "7        61\n",
      "7        62\n",
      "7        63\n",
      "7        64\n",
      "7        65\n",
      "7        66\n",
      "7        67\n",
      "7        68\n",
      "7        69\n",
      "7        70\n",
      "7        71\n",
      "7        72\n",
      "7        73\n",
      "7        74\n",
      "7        75\n",
      "7        76\n",
      "7        77\n",
      "7        78\n",
      "7        79\n",
      "7        80\n",
      "7        81\n",
      "7        82\n",
      "7        83\n",
      "7        84\n",
      "7        85\n",
      "7        86\n",
      "7        87\n",
      "7        88\n",
      "7        89\n",
      "7        90\n",
      "7        91\n",
      "7        92\n",
      "7        93\n",
      "7        94\n",
      "7        95\n",
      "7        96\n",
      "7        97\n",
      "7        98\n",
      "7        99\n",
      "8        0\n",
      "8        1\n",
      "8        2\n",
      "8        3\n",
      "8        4\n",
      "8        5\n",
      "8        6\n",
      "8        7\n",
      "8        8\n",
      "8        9\n",
      "8        10\n",
      "8        11\n",
      "8        12\n",
      "8        13\n",
      "8        14\n",
      "8        15\n",
      "8        16\n",
      "8        17\n",
      "8        18\n",
      "8        19\n",
      "8        20\n",
      "8        21\n",
      "8        22\n",
      "8        23\n",
      "8        24\n",
      "8        25\n",
      "8        26\n",
      "8        27\n",
      "8        28\n",
      "8        29\n",
      "8        30\n",
      "8        31\n",
      "8        32\n",
      "8        33\n",
      "8        34\n",
      "8        35\n",
      "8        36\n",
      "8        37\n",
      "8        38\n",
      "8        39\n",
      "8        40\n",
      "8        41\n",
      "8        42\n",
      "8        43\n",
      "8        44\n",
      "8        45\n",
      "8        46\n",
      "8        47\n",
      "8        48\n",
      "8        49\n",
      "8        50\n",
      "8        51\n",
      "8        52\n",
      "8        53\n",
      "8        54\n",
      "8        55\n",
      "8        56\n",
      "8        57\n",
      "8        58\n",
      "8        59\n",
      "8        60\n",
      "8        61\n",
      "8        62\n",
      "8        63\n",
      "8        64\n",
      "8        65\n",
      "8        66\n",
      "8        67\n",
      "8        68\n",
      "8        69\n",
      "8        70\n",
      "8        71\n",
      "8        72\n",
      "8        73\n",
      "8        74\n",
      "8        75\n",
      "8        76\n",
      "8        77\n",
      "8        78\n",
      "8        79\n",
      "8        80\n",
      "8        81\n",
      "8        82\n",
      "8        83\n",
      "8        84\n",
      "8        85\n",
      "8        86\n",
      "8        87\n",
      "8        88\n",
      "8        89\n",
      "8        90\n",
      "8        91\n",
      "8        92\n",
      "8        93\n",
      "8        94\n",
      "8        95\n",
      "8        96\n",
      "8        97\n",
      "8        98\n",
      "8        99\n",
      "9        0\n",
      "9        1\n",
      "9        2\n",
      "9        3\n",
      "9        4\n",
      "9        5\n",
      "9        6\n",
      "9        7\n",
      "9        8\n",
      "9        9\n",
      "9        10\n",
      "9        11\n",
      "9        12\n",
      "9        13\n",
      "9        14\n",
      "9        15\n",
      "9        16\n",
      "9        17\n",
      "9        18\n",
      "9        19\n",
      "9        20\n",
      "9        21\n",
      "9        22\n",
      "9        23\n",
      "9        24\n",
      "9        25\n",
      "9        26\n",
      "9        27\n",
      "9        28\n",
      "9        29\n",
      "9        30\n",
      "9        31\n",
      "9        32\n",
      "9        33\n",
      "9        34\n",
      "9        35\n",
      "9        36\n",
      "9        37\n",
      "9        38\n",
      "9        39\n",
      "9        40\n",
      "9        41\n",
      "9        42\n",
      "9        43\n",
      "9        44\n",
      "9        45\n",
      "9        46\n",
      "9        47\n",
      "9        48\n",
      "9        49\n",
      "9        50\n",
      "9        51\n",
      "9        52\n",
      "9        53\n",
      "9        54\n",
      "9        55\n",
      "9        56\n",
      "9        57\n",
      "9        58\n",
      "9        59\n",
      "9        60\n",
      "9        61\n",
      "9        62\n",
      "9        63\n",
      "9        64\n",
      "9        65\n",
      "9        66\n",
      "9        67\n",
      "9        68\n",
      "9        69\n",
      "9        70\n",
      "9        71\n",
      "9        72\n",
      "9        73\n",
      "9        74\n",
      "9        75\n",
      "9        76\n",
      "9        77\n",
      "9        78\n",
      "9        79\n",
      "9        80\n",
      "9        81\n",
      "9        82\n",
      "9        83\n",
      "9        84\n",
      "9        85\n",
      "9        86\n",
      "9        87\n",
      "9        88\n",
      "9        89\n",
      "9        90\n",
      "9        91\n",
      "9        92\n",
      "9        93\n",
      "9        94\n",
      "9        95\n",
      "9        96\n",
      "9        97\n",
      "9        98\n",
      "9        99\n"
     ]
    }
   ],
   "source": [
    "### 迭代模型\n",
    "n = 2557 # 2556应根据数据集实际大小决定\n",
    "for i in range(1, k):\n",
    "    dataloader = DataLoader(NWSDataset(fake=fake_name, c=c, i=i, n=n), batch_size=256, shuffle=True)\n",
    "    for epoch in range(0, 100):\n",
    "        print(i,\"      \",epoch)\n",
    "        for realdata in dataloader:\n",
    "            noise = 1e-5 * max(1 - (epoch / 100.0), 0)\n",
    "            step += 1\n",
    "            batch_size = realdata[0].shape[0]\n",
    "            trueTensor = 0.7 + 0.5 * torch.rand(batch_size)\n",
    "            falseTensor = 0.3 * torch.rand(batch_size)\n",
    "            probFlip = torch.rand(batch_size) < 0.05\n",
    "            probFlip = probFlip.float()\n",
    "            trueTensor, falseTensor = (\n",
    "                probFlip * falseTensor + (1 - probFlip) * trueTensor,\n",
    "                probFlip * trueTensor + (1 - probFlip) * falseTensor,\n",
    "            )\n",
    "            trueTensor = trueTensor.view(-1, 1).cuda(gpu_id)\n",
    "            falseTensor = falseTensor.view(-1, 1).cuda(gpu_id)\n",
    "            realdata = realdata.cuda(gpu_id)\n",
    "            realSource = D(realdata)\n",
    "            realLoss = criterionSource(realSource, trueTensor.expand_as(realSource))\n",
    "            latent = Variable(torch.randn(batch_size, latentdim, 1, 1)).cuda(gpu_id)\n",
    "            fakeGen = G(latent)\n",
    "            fakeGenSource = D(fakeGen.detach())\n",
    "            fakeGenLoss = criterionSource(fakeGenSource, falseTensor.expand_as(fakeGenSource))\n",
    "            lossD = realLoss + fakeGenLoss\n",
    "            optimizerD.zero_grad()\n",
    "            lossD.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(D.parameters(), 20)\n",
    "            optimizerD.step()\n",
    "            fakeGenSource = D(fakeGen)\n",
    "            lossG = criterionSource(fakeGenSource, trueTensor.expand_as(fakeGenSource))\n",
    "            optimizerG.zero_grad()\n",
    "            lossG.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(G.parameters(), 20)\n",
    "            optimizerG.step()\n",
    "            board.add_scalar('realLoss', realLoss.item(), step)\n",
    "            board.add_scalar('fakeGenLoss', fakeGenLoss.item(), step)\n",
    "            board.add_scalar('lossD', lossD.item(), step)\n",
    "            board.add_scalar('lossG', lossG.item(), step)\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            torch.save(G.state_dict(), DIRNAME + \"Gstage\" + str(i) + 'epoch' + str(epoch) + \".pt\")\n",
    "            torch.save(D.state_dict(), DIRNAME + \"Dstage\" + str(i) + 'epoch' + str(epoch) + \".pt\")\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "                G.eval()\n",
    "                sample_image(i, epoch)\n",
    "                G.train()\n",
    "    with torch.no_grad():\n",
    "        G.eval()\n",
    "        fsize = int((1 - (c ** (i + 1))) * n / c)\n",
    "        fakeSamples = G(Variable(torch.randn(fsize, latentdim, 1, 1)).cuda(gpu_id))\n",
    "        sums = fakeSamples.sum(dim=(1, 2, 3)).detach().cpu().numpy().argsort()[::-1].copy()\n",
    "        fake_name = DIRNAME + 'fake' + str(i + 1) + '.pt'\n",
    "        torch.save(fakeSamples.data[sums], fake_name)\n",
    "        del fakeSamples\n",
    "        G.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
